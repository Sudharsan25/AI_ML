{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64508bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Neural network:\n",
    "x --> input (1)\n",
    "wx --> weights (2)\n",
    "bx --> bias (3)\n",
    "A --> Activation function (4)\n",
    "Y --> Output (5)\n",
    "\n",
    "# one forward pass\n",
    "Z = wx.x + bx\n",
    "Z' = A(z)\n",
    "Y = Wx.Z' + bx\n",
    "\n",
    "# after output, loss needs to be calculated --> Loss function (5)\n",
    "# gradients for loss are calculated using backpropagation (6)\n",
    "# gradients are updated --> Optimizers (7)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Components of Pytorch\n",
    "\n",
    "Base class for defining any models in PyTorch : torch.nn.Module\n",
    "Fully connected (dense) layers: torch.nn.Linear\n",
    "Activation functions: torch.nn.ReLU\n",
    "Optimser: torch.optim\n",
    "Loss function: torch.nn.CrossEntropyLoss\n",
    "Load data in batches: torch.utils.data.DataLoader\n",
    "'''\n",
    "\n",
    "'''\n",
    "Different ways to create Neural networks\n",
    "1. Functional --> torch.nn.Functional (flexible)\n",
    "2. Sequential --> torch.nn.Sequential \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b6edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functional method\n",
    "\n",
    "class FirstNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): ## used to initalize layers\n",
    "        super(FirstNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # First fully connected layers with input_size incoming neurons and hidden_size outgoing neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Second FC layer with hidden_size incoming neurons (from previous layer) and output_size outgoing neurons\n",
    "    \n",
    "    def forward():\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
